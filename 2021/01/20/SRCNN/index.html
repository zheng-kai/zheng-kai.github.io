
 <!DOCTYPE HTML>
<html lang="en">
<head>
  <meta charset="UTF-8">
  
    <title>超分辨-SRCNN | Zheng Kai&#39;s blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Zheng Kai">
    

    
    <meta name="description" content="​	实现超分辨率重建的算法有很多，包括经典的基于插值的方法，如双立方插值。而基于机器学习的算法SRCNN可以达到比插值更好的效果。">
<meta property="og:type" content="article">
<meta property="og:title" content="超分辨-SRCNN">
<meta property="og:url" content="https://zheng-kai.github.io/2021/01/20/SRCNN/index.html">
<meta property="og:site_name" content="Zheng Kai&#39;s blog">
<meta property="og:description" content="​	实现超分辨率重建的算法有很多，包括经典的基于插值的方法，如双立方插值。而基于机器学习的算法SRCNN可以达到比插值更好的效果。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zheng-kai.github.io/2021/01/20/SRCNN/srcnn_net.png">
<meta property="og:image" content="https://zheng-kai.github.io/2021/01/20/SRCNN/bird_GT.bmp">
<meta property="og:image" content="https://zheng-kai.github.io/2021/01/20/SRCNN/bird_GT_zoom3.bmp">
<meta property="article:published_time" content="2021-01-20T07:45:36.000Z">
<meta property="article:modified_time" content="2024-03-24T07:00:06.972Z">
<meta property="article:author" content="Zheng Kai">
<meta property="article:tag" content="图像处理">
<meta property="article:tag" content="卷积神经网络">
<meta property="article:tag" content="作业记录">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zheng-kai.github.io/2021/01/20/SRCNN/srcnn_net.png">

    
    <link rel="alternative" href="/atom.xml" title="Zheng Kai&#39;s blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 7.1.1"></head>

  <body>
    <header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Zheng Kai&#39;s blog">Zheng Kai&#39;s blog</a></h1>
				<h2 class="blog-motto">life is short</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
					<li>
 					
					<!-- <form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:zheng-kai.github.io">
					</form> -->
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <div class="container">
    <p class="article-title" itemprop="name">
      
        <a href="/2021/01/20/SRCNN/" title="超分辨-SRCNN" itemprop="url">超分辨-SRCNN</a>
    </p>
    <p class="article-time">
      <time datetime="2021-01-20T07:45:36.000Z" itemprop="datePublished"> Published 2021-01-20</time>
    </p>
    <p class="article-author">By
      
      <a href="/about" title="Zheng Kai" target="_blank" itemprop="author">Zheng Kai</a>
      
    </p>
  </div>

</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">Contents</strong>
		
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%9F%E7%90%86%E9%98%90%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">原理阐述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">1.1.</span> <span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E7%9A%84%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.2.</span> <span class="toc-text">图片数据的预处理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90"><span class="toc-number">2.</span> <span class="toc-text">算法分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">3.</span> <span class="toc-text">实验结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%80%9D%E8%80%83"><span class="toc-number">4.</span> <span class="toc-text">问题思考</span></a></li></ol>
		
		</div>
		
		<p>​	实现超分辨率重建的算法有很多，包括经典的基于插值的方法，如双立方插值。而基于机器学习的算法SRCNN可以达到比插值更好的效果。</p>
<span id="more"></span>

<h2 id="原理阐述"><a href="#原理阐述" class="headerlink" title="原理阐述"></a>原理阐述</h2><p>​	使用卷积神经网络训练模型，将上采样图像转化为高分辨率图像。其中上采样图像使用双立方插值对原图进行放大得到，而转化成的高分辨率图像虽然和上采样图像大小一样，但比三次立方插值放大得到的图像清晰，因此SRCNN成为了比双立方插值效果更好的方法。</p>
<p>​	假设存在一种模糊图像到高分辨率图像的映射关系，该神经网络的目的就是求解出这个映射关系。因为图像通常使用矩阵表示，不同的图像对应着不同的矩阵，图像的特点可以使用矩阵的特征表示。而图像千变万化，如果使用小矩阵来拆解图像，使用多个小矩阵来表示一个图像的话，那么所有的图像都可以用这些小矩阵来表示了。所以该神经网络只要可以对小矩阵进行处理，将其映射成高分辨率的小矩阵，即可将图像从模糊映射成高清。因为双立方插值放大的图像并不清晰，结合该方法，即可实现得到放大的清晰图片的效果。</p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>SRCNN网络分为三层，每层的功能如下：</p>
<ol>
<li><p>提取和表示图像块：</p>
<p>​	该卷积层的输入数据为拆分好的图像块的Y通道。</p>
<p>​	该层负责提取图像块的特征。特征个数为$n_1$，该层卷积核大小为$f_1*f_1$</p>
</li>
<li><p>非线性映射</p>
<p>​	该卷积层将上一层的$n_1$个特征进行非线性映射，映射为$n_2$个特征，该层卷积核大小为$f_2*f_2$</p>
</li>
<li><p>重建</p>
<p>​	该卷积层将会把上一层的$n_2$个特征映射为高分辨率图像的Y通道。该层卷积核大小为$f_3*f_3$</p>
</li>
</ol>
<p><img src="/2021/01/20/SRCNN/srcnn_net.png"></p>
<h3 id="图片数据的预处理"><a href="#图片数据的预处理" class="headerlink" title="图片数据的预处理"></a>图片数据的预处理</h3><p>训练集和测试集的数据需要根据算法从图片中采集。</p>
<p>因为进行卷积操作，输出的数据矩阵会比输入矩阵的维度小，所以标签数据要比上采样图像小<code>(f1//2 + f2//2 + f3//2)*2</code>。</p>
<ul>
<li><p>标签数据和上采样图像的来源</p>
<p>​	将下载好的图片作为<strong>标签数据</strong>。</p>
<p>​	<strong>上采样图像</strong>为原图通过双立方插值的方法，缩小$scale$倍再放大$scale$倍，得到的和原图大小相同的模糊图像。</p>
</li>
<li><p>处理方式</p>
<p>​	将每张图片按照特定步长分割成小方块，上采样图像和标签图像的小方块一一对应，最后将所有数据打乱顺序，存储在本地文件中。使用相同的方式将不同的两组图片集分别做成<strong>训练集</strong>和<strong>测试集</strong>。</p>
</li>
</ul>
<h2 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a>算法分析</h2><ul>
<li><p>数据预处理</p>
<p>​	为了减少模型训练的时间，仅使用了一部分SRCNN官方论文提供的图片作为数据源。分别对其中的45张和77张进行了处理，生成两组训练数据集，分别为<code>train2.h5</code>，<code>train3.h5</code>。</p>
<p>​	处理时，将每一张图片进行上采样，并将上采样结果拆分成许多$33<em>33$大小的方块作为训练集上采样图像。同时将原图对应位置的$33</em>33$方块中心的$21*21$大小的方块作为训练集的标签。两个对应的方块作为一对，最终将所有数据按照对为基本单位进行打乱，存储在hdf5文件中。其中33和21的大小设置参考的SRCNN论文，理论上大小是可以修改的，只要两者的差值等于<code>(f1//2 + f2//2 + f3//2)*2</code>即可。</p>
<p>​	测试集数据的处理同上。使用的测试数据集为$Set5$。</p>
</li>
<li><p>训练模型</p>
<p>​	首先使用pytorch进行卷积神经网络的搭建。因为卷积操作会缩小图片，在测试模型时，为了保证输入输出的维度大小一致，为卷积核增加了padding。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SRCNN</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, isTrain</span>):</span><br><span class="line">        <span class="built_in">super</span>(SRCNN, self).__init__()</span><br><span class="line">        c = <span class="number">1</span></span><br><span class="line">        n1 = <span class="number">32</span></span><br><span class="line">        n2 = <span class="number">16</span></span><br><span class="line">        <span class="keyword">if</span> isTrain:</span><br><span class="line">            self.conv1 = nn.Conv2d(c, n1, <span class="number">9</span>)</span><br><span class="line">            self.conv2 = nn.Conv2d(n1, n2, <span class="number">1</span>)</span><br><span class="line">            self.conv3 = nn.Conv2d(n2, c, <span class="number">5</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.conv1 = nn.Conv2d(c, n1, <span class="number">9</span>, padding=<span class="number">9</span> // <span class="number">2</span>)</span><br><span class="line">            self.conv2 = nn.Conv2d(n1, n2, <span class="number">1</span>)</span><br><span class="line">            self.conv3 = nn.Conv2d(n2, c, <span class="number">5</span>, padding=<span class="number">5</span> // <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.relu(self.conv1(x))</span><br><span class="line">        x = self.relu(self.conv2(x))</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<p>​	训练时，将训练集数据的batch大小设为128，测试集为2。模型的损失函数采用MSE函数。使用学习率为0.0001的Adam进行模型参数优化。</p>
<p>​	因为训练模型花费时间过长，本次作业使用<code>train2.h5</code>分别进行了进行20轮和50轮训练，使用<code>train3.h5</code>进行5轮和30轮训练。其中<code>train3.h5</code>使用<code>n1=64,n2=32</code>来训练模型。</p>
</li>
<li><p>测试模型</p>
<p>​	将图片使用立方插值的方式缩小，作为小图，原图片作为大图。只要使用原图与测试模型得到的放大结果计算PSNR值，即可量化模型的判断标准，并且可以与立方插值方法进行对比。其中需要注意的是，测试模型时为了保证得到的图片和原图大小一样，需要为卷积核设置padding，这是训练模型时不需要的。同时，因为放大图片会导致图片边缘的像素计算不准确，在计算PSNR时，需要根据放大倍数对图像的边界进行裁剪。令人感到遗憾的是，我训练出来的这几个模型，PSNR值均未超过双立方插值的。</p>
</li>
</ul>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>​	训练出的四个模型分别放在项目目录下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model:sr3 使用n1=64 n2=32, train3.h5训练集 训练5轮，测试模型得到的PSNR值</span><br><span class="line">PSNR model: 30.78</span><br><span class="line">PSNR cubic: 31.16</span><br><span class="line">model:sr2 使用n1=32 n2=16, train3.h5训练集 训练30轮，测试模型得到的PSNR值</span><br><span class="line">PSNR model: 30.97</span><br><span class="line">PSNR cubic: 31.16</span><br><span class="line">model:sr1_1 使用n1=32 n2=16, train2.h5训练集 训练20轮，测试模型得到的PSNR值</span><br><span class="line">PSNR model: 30.22</span><br><span class="line">PSNR cubic: 31.16</span><br><span class="line">model:sr 使用n1=32 n2=16, train2.h5训练集 训练50轮，测试模型得到的PSNR值</span><br><span class="line">PSNR model: 30.63</span><br><span class="line">PSNR cubic: 31.16	</span><br></pre></td></tr></table></figure>

<p>​	虽然模型的效果并不如二次立方插值，但是PSNR值在30以上，还算可以接受吧..</p>
<ul>
<li><p>原图</p>
<p><img src="/2021/01/20/SRCNN/bird_GT.bmp" alt="bird_GT"></p>
</li>
<li><p>放大3倍得到的图片</p>
<p><img src="/2021/01/20/SRCNN/bird_GT_zoom3.bmp" alt="bird_GT_zoom3"></p>
</li>
</ul>
<h2 id="问题思考"><a href="#问题思考" class="headerlink" title="问题思考"></a>问题思考</h2><p>​	因为看论文中模型得到的结果还是很不错的，PSNR值能达到32.26，但是我的模型效果就没有那么好，最好的模型只有30.97，还不如双三次插值的效果好。分析影响模型效果的因素有：$n_1,n_2$的选取，模型训练的轮数，数据集的大小。虽然该神经网络模型只有三层，但由于没有找到适合本机的支持gpu的pytorch版本，训练模型使用cpu进行计算，速度很慢。为了减少时长，我并没有使用论文中提供的全部91张图片作为训练数据，也并没有采用论文中说的$n_1&#x3D;64,n_2&#x3D;32$来训练，而是减半。训练的轮数也并没有很多。可能这就是我的模型效果不好的原因吧。因为随着训练轮数的增加，PSNR数值的增长会变慢，所以为了得到论文中那样的结果，可能需要使用91张照片的全数据集训练上百轮或千轮才能得到。</p>
<pre><code>参考论文：Chao DongChen Change LoyKaiming HeXiaoou Tang ：Learning a Deep Convolutional Network for Image Super-Resolution
</code></pre>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/AI/">AI</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/图像处理/">图像处理</a><a href="/tags/卷积神经网络/">卷积神经网络</a><a href="/tags/作业记录/">作业记录</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="https://zheng-kai.github.io/2021/01/20/SRCNN/" data-title="超分辨-SRCNN | Zheng Kai&#39;s blog" data-tsina="" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2021/05/19/css-块级行内元素/" title="css-块级行内元素">
  <strong>上一篇：</strong><br/>
  <span>
  css-块级行内元素</span>
</a>
</div>


<div class="next">
<a href="/2020/11/07/Java-面向对象入门/"  title="Java 面向对象入门">
 <strong>下一篇：</strong><br/> 
 <span>Java 面向对象入门
</span>
</a>
</div>

</nav>

	



</div>  
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">Contents</strong>
 
 <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%9F%E7%90%86%E9%98%90%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">原理阐述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">1.1.</span> <span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E7%9A%84%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.2.</span> <span class="toc-text">图片数据的预处理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90"><span class="toc-number">2.</span> <span class="toc-text">算法分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">3.</span> <span class="toc-text">实验结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%80%9D%E8%80%83"><span class="toc-number">4.</span> <span class="toc-text">问题思考</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  
<div class="categorieslist">
	<p class="asidetitle">Categories</p>
		<ul>
		
		  
			<li><a href="/categories/AI/" title="AI">AI<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/java/" title="java">java<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/前端/" title="前端">前端<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/杂记/" title="杂记">杂记<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/算法/" title="算法">算法<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/静态分析/" title="静态分析">静态分析<sup>1</sup></a></li>
		  
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/java/" title="java">java<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/学习笔记/" title="学习笔记">学习笔记<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/instrument/" title="instrument">instrument<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/面向对象/" title="面向对象">面向对象<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/图像处理/" title="图像处理">图像处理<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/卷积神经网络/" title="卷积神经网络">卷积神经网络<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/作业记录/" title="作业记录">作业记录<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/css/" title="css">css<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/dom/" title="dom">dom<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/jvm/" title="jvm">jvm<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/gc/" title="gc">gc<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/static-analysis/" title="static analysis">static analysis<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/data-flow-analysis/" title="data flow analysis">data flow analysis<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/数据结构/" title="数据结构">数据结构<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/前缀和/" title="前缀和">前缀和<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/javassist/" title="javassist">javassist<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
        
          <li>
            
            	<a href="https://github.com/zheng-kai" target="_blank" title="GitHub">GitHub</a>
            
          </li>
        
          <li>
            
            	<a href="https://gitee.com/AlexAnde" target="_blank" title="Gitee">Gitee</a>
            
          </li>
        
    </ul>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Zheng Kai. <br/>
			Speeches are for campaigning. Now is the time for action.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		<a href="https://github.com/zheng-kai" target="_blank" class="icon-github" title="github"></a>
		
		
		
		
		
		
		
		
		
		<a href="mailto:272991962@qq.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2024 
		
		<a href="/about" target="_blank" title="Zheng Kai">Zheng Kai</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>











<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="Back to Top"><img src="/img/scrollup.svg"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
</html>
